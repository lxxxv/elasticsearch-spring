http://sooyeol86.blogspot.com/2019/12/elasticsearch-nori.html

E : 어미 [Verbal endings]
    어간 뒤에 놓이는 굴절 접사
    ex) 하고,다,습니다,있,었
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/EC.csv
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/EF.csv
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/EP.csv
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/ETM.csv
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/ETN.csv

IC : 감탄사 [Interjection]
    말하는 이의 본능적인 놀람이나 느낌, 부름, 응답 따위를 나타내는 말의 부류
    ex) 만세,맙소사,아이고
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/IC.csv

J : 조사 [Ending Particle]
    주로 체언에 붙어 뒤에 오는 다른 단어에 대하여 가지는 문법적 관계를 표시하거나 그 말의 뜻을 도와주는 품사
    ex) ~보다,~까지
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/J.csv

MAG : 부사 [General Adverb]
    동사, 형용사, 동사구, 문장 전체를 수식하는 역할을 맡는 품사
    ex) 힘껏,즉시,번쩍
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/MAG.csv

MAJ : 접속부사 [Conjunctive adverb]
    문장과 문장 사이를 접속해(연이어) 주는 부사
    ex) 그러나,왜냐하면,그리고
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/MAJ.csv

MM : 관형사 [Determiner]
    체언 앞에 놓여서, 그 체언의 내용을 자세히 꾸며 주는 품사
    ex) 저,갓,그딴,수천수만
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/MM.csv

NNB : 의존명사 [Dependent noun(following nouns)]
    의미가 형식적이어서 다른 말 아래에 기대어 쓰이는 명사
    ex) 것,따름,동안,무렵,이상
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/NNB.csv

NNBC : 분류사 [Dependent noun]
    단위를 나타내는 명사
    ex) 퍼센트,군단
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/NNBC.csv

NNG : 보통명사 [General Noun]
    일반 개념을 표시하는 명사. 여러 가지 사물의 공통된 특성을 나타낸다
    https://raw.githubusercontent.com/hephaex/mecab-ko/master/mecab-ko-dic/seed/NNG.csv

NNP : 고유명사 [Proper Noun]
    특정한 대상이나 유일한 대상을 가리키는 명사의 일종.
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/NNP.csv

NP : 대명사 [Pronoun]
    사람이나 사물, 장소를 직접 가리키는 기능을 하는 품사
    ex) 이것저것,귀하,그거
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/NP.csv

NR : 수사 [Numeral]
    사물의 수량이나 순서를 나타내는 단어의 한 부류
    ex) 경,십,예닐곱,오륙백
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/NR.csv

VA : 형용사 [Adjective]
    품사의 하나로 사람이나 사물의 성질과 상태 또는 존재를 나타내는 말
    ex) 가녀린,잔망스럽,올바른
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/VA.csv

VCN : 부정 지정사 [Negative designator]
    지정사 : 어떤 대상을 지정할 때 사용하는 ‘이다’와 ‘아니다’를 가리키는 품사
    ex) 아니,아닌
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/VCN.csv

VCP : 긍정 지정사 [Positive designator]
    ex) 이,보이,사이
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/VCP.csv

VV : 동사 [Verb]
    사람이나 사물의 움직임 또는 작용을 나타내는 말
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/VV.csv

VX : 보조용언 [Auxiliary Verb or Adjective]
    조적 기능을 수행하는 동사의 부류. 즉 뒤에 있는 동사구가 앞의 동사에 어떤 보조의 의미를 첨가하는 기능을 한다
    ex) 헷갈리,잡수
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/VX.csv

XPN : 체언접두사 [Prefix]
    체언 : 조사의 도움을 받아 문장에서 주체의 구실을 하는 단어
    ex) 새 (새 것, 새 날)
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/XPN.csv

XR : 어근 [Root]
    단어의 실질적 의미를 나타내는 중심 부분
    ex) 불그스름,희뿌염,일목요염
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/XR.csv

XSA : 형용사 파생 접미사 [Adjective Suffix]
    접미사 : 접사의 하나로 낱말의 끝에 붙어 의미를 첨가하여 다른 낱말을 이루는 말
    ex) 못마땅하,스럽
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/XSA.csv

XSN : 명사 파생 접미사 [Noun Suffix]
    ex) 치레,투성이
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/XSN.csv

XSV : 동사 파생 접미사 [Verb Suffix]
    ex) 되잖,시키
    https://github.com/hephaex/mecab-ko/blob/master/mecab-ko-dic/seed/XSV.csv

NA, UNA, Unknown, VSV : 알수없는 [unknown]
    SC : 구분기호 [Separator (· / :)]
    SE : 생략 [Ellipsis]
    SF : 물음표,느낌표,마침표 [Terminal punctuation (? ! .)]
    SH : 한자 [Chinese character]
    SL : 외국어 [Foreign language]
    SN : 숫자 [Number]
    SP : 공백 [Space]
    SSC 닫는 괄호 [Closing brackets]
    SSO : 여는 괄호 [Opening brackets]
    SY : 기타 기호 [Other symbol]

노리 플러그인 설치
    # elasticsearch-plugin install analysis-nori
노리 플러그인 제거
    # elasticsearch-plugin remove analysis-nori


standard tokenizer
    요청
    GET _analyze
    {
        "tokenizer": "standard",
        "text": ["동해물과 백두산이"],
        "explain": true
    }
    결과
    {
        "tokens" :
        [
            {
                "token" : "동해물과",
                "start_offset" : 0,
                "end_offset" : 4,
                "type" : "<HANGUL>",
                "position" : 0
            },
            {
                "token" : "백두산이",
                "start_offset" : 5,
                "end_offset" : 9,
                "type" : "<HANGUL>",
                "position" : 1
            }
        ]
    }

nori tokenizer
    요청
    GET _analyze
    {
        "tokenizer": "nori_tokenizer",
        "text": ["동해물과 백두산이"]
    }
    결과
    {
        "tokens" :
        [
            {
                "token" : "동해",
                "start_offset" : 0,
                "end_offset" : 2,
                "type" : "word",
                "position" : 0
            },
            {
                "token" : "물",
                "start_offset" : 2,
                "end_offset" : 3,
                "type" : "word",
                "position" : 1
            },
            {
                "token" : "과",
                "start_offset" : 3,
                "end_offset" : 4,
                "type" : "word",
                "position" : 2
            },
            {
                "token" : "백두",
                "start_offset" : 5,
                "end_offset" : 7,
                "type" : "word",
                "position" : 3
            },
            {
                "token" : "산",
                "start_offset" : 7,
                "end_offset" : 8,
                "type" : "word",
                "position" : 4
            },
            {
                "token" : "이",
                "start_offset" : 8,
                "end_offset" : 9,
                "type" : "word",
                "position" : 5
            }
        ]
    }

옵션
    요청
    PUT my_nori
    {
        "settings":
        {
            "analysis":
            {
                "tokenizer":
                {
                    "nori_none":
                    {
                        "type": "nori_tokenizer",
                        "decompound_mode": "none"
                    },
                    "nori_discard":
                    {
                        "type": "nori_tokenizer",
                        "decompound_mode": "discard"
                    },
                    "nori_mixed":
                    {
                        "type": "nori_tokenizer",
                        "decompound_mode": "mixed"
                    }
                }
            }
        }
    }
    결과
    GET  /my_nori/_analyze
    {
        "tokenizer" : "nori_mixed",
        "text" : "동해물과 백두산이",
        "explain" : true
    }


"text": [ "백두산이" ]
    nori_none
    {
        "tokens" :
        [
            {
                "token" : "백두산",
                "start_offset" : 0,
                "end_offset" : 3,
                "type" : "word",
                "position" : 0
            },
            {
                "token" : "이",
                "start_offset" : 3,
                "end_offset" : 4,
                "type" : "word",
                "position" : 1
            }
        ]
    }

    nori_discard
    {
        "tokens" :
        [
            {
                "token" : "백두",
                "start_offset" : 0,
                "end_offset" : 2,
                "type" : "word",
                "position" : 0
            },
            {
                "token" : "산",
                "start_offset" : 2,
                "end_offset" : 3,
                "type" : "word",
                "position" : 1
            },
            {
                "token" : "이",
                "start_offset" : 3,
                "end_offset" : 4,
                "type" : "word",
                "position" : 2
            }
        ]
    }

    nori_mixed
    {
        "tokens" :
        [
            {
                "token" : "백두산",
                "start_offset" : 0,
                "end_offset" : 3,
                "type" : "word",
                "position" : 0,
                "positionLength" : 2
            },
            {
                "token" : "백두",
                "start_offset" : 0,
                "end_offset" : 2,
                "type" : "word",
                "position" : 0
            },
            {
                "token" : "산",
                "start_offset" : 2,
                "end_offset" : 3,
                "type" : "word",
                "position" : 1
            },
            {
                "token" : "이",
                "start_offset" : 3,
                "end_offset" : 4,
                "type" : "word",
                "position" : 2
            }
        ]
    }



Analyzer API
    GET  /_analyze
    POST /_analyze
    GET  /<index>/_analyze
    POST /<index>/_analyze


